{"cells":[{"cell_type":"markdown","metadata":{"id":"XGV-KL6pL1nE"},"source":["# SparkSession vs SparkContext"]},{"cell_type":"markdown","metadata":{"id":"_KYu3hrML1nG"},"source":["## Importamos SparkContext y SparkSession"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6T70QOZhL1nH","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"error","timestamp":1689159249133,"user_tz":-120,"elapsed":40312,"user":{"displayName":"Gulnat Pettit","userId":"18321854524752889820"}},"outputId":"70ef02e9-da7b-4128-b775-44d0470c438d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5f3bfc9a0cf6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install pyspark --quiet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["!pip install pyspark --quiet\n","from pyspark import SparkContext\n","from pyspark.sql import SparkSession"]},{"cell_type":"markdown","metadata":{"id":"chASV6-OL1nI"},"source":["## Creamos nuestra primera sesion"]},{"cell_type":"markdown","source":["En Apache Spark, una **sesión es una conexión de un cliente con el cluster Spark**. La sesión se utiliza para enviar trabajos al cluster y obtener resultados de ellos. Una sesión se puede iniciar de forma interactiva desde la línea de comandos o programáticamente desde una aplicación de Spark.\n","\n","Un **contexto de Spark** es un objeto que representa una conexión a un cluster Spark y proporciona un punto de acceso a todas las funcionalidades de Spark. En una aplicación de Spark, normalmente se crea un contexto al principio del programa y se utiliza para realizar todas las operaciones de Spark en esa aplicación. Por ejemplo, podrías utilizar un contexto para crear un conjunto de datos (RDD), aplicar transformaciones y acciones sobre él y obtener resultados.\n","\n","Es importante mencionar que **una sesión puede tener múltiples contextos**, y que cada contexto se puede utilizar para realizar operaciones de Spark de forma independiente. Por ejemplo, podrías tener un contexto para procesar datos en tiempo real y otro contexto para realizar análisis en lote."],"metadata":{"id":"WrkEikPTe4Bu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKjXd8P6L1nI","executionInfo":{"status":"aborted","timestamp":1689159249134,"user_tz":-120,"elapsed":40746,"user":{"displayName":"Gulnat Pettit","userId":"18321854524752889820"}}},"outputs":[],"source":["#Convenio\n","#Sesión --> spark\n","#Contexto --> sc\n","\n","spark = SparkSession.builder \\\n","        .master(\"local\") \\\n","        .appName(\"miPrimerApplicacion\") \\\n","        .getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"F3614c6xL1nI"},"source":["## Terminamos la sesión actual\n","\n","No podemos tener mas de una sesión a la vez en nuestro notebook, por lo cual con el método 'stop' terminaremos la applicación.\n","\n","De la misma forma, al terminar una applicación, debemos de indicar explicitamente que termine. De otra forma no liberará los recursos asignados."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3iVqN4pL1nJ","executionInfo":{"status":"aborted","timestamp":1689159249134,"user_tz":-120,"elapsed":40745,"user":{"displayName":"Gulnat Pettit","userId":"18321854524752889820"}}},"outputs":[],"source":["spark.stop()"]},{"cell_type":"markdown","metadata":{"id":"Dl01ZDfnL1nJ"},"source":["## Creamos una sesión heredando los atributos de un contexto"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NhQR5VG1L1nK","executionInfo":{"status":"aborted","timestamp":1689159249135,"user_tz":-120,"elapsed":40743,"user":{"displayName":"Gulnat Pettit","userId":"18321854524752889820"}}},"outputs":[],"source":["sc = SparkContext(master=\"local\",appName = \"miPrimerContexto\")\n","spark2 = SparkSession(sc)"]},{"cell_type":"code","source":["spark2"],"metadata":{"id":"8Gsb4FRtQhpo","executionInfo":{"status":"aborted","timestamp":1689159249135,"user_tz":-120,"elapsed":40729,"user":{"displayName":"Gulnat Pettit","userId":"18321854524752889820"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nD83MOvNL1nL"},"source":["## Creamos una sesión múltiple"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VO00IauNL1nL","executionInfo":{"status":"aborted","timestamp":1689159249135,"user_tz":-120,"elapsed":40725,"user":{"displayName":"Gulnat Pettit","userId":"18321854524752889820"}}},"outputs":[],"source":["sparkSession2 = spark2.newSession()"]},{"cell_type":"markdown","metadata":{"id":"2Hzhe1urL1nL"},"source":["## Revisamos que los tres objetos apuntan a la misma aplicación\n","\n","Aprovechando la salida que nos ofrece, conocemos SparkUI, el monitor por excelencia para Spark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QKY6nAKL1nM","executionInfo":{"status":"aborted","timestamp":1689159249136,"user_tz":-120,"elapsed":40720,"user":{"displayName":"Gulnat Pettit","userId":"18321854524752889820"}}},"outputs":[],"source":["spark2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rVK2gmt9L1nM","executionInfo":{"status":"aborted","timestamp":1689159249136,"user_tz":-120,"elapsed":40716,"user":{"displayName":"Gulnat Pettit","userId":"18321854524752889820"}}},"outputs":[],"source":["spark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehCs3bdfL1nN"},"outputs":[],"source":["sparkSession2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LAqMi_scL1nN"},"outputs":[],"source":["spark2.stop()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[{"file_id":"1FQBpyj1VzOABDDIEjebh967b5ZuRqiJS","timestamp":1689151958484},{"file_id":"https://github.com/terranigmark/curso-apache-spark-platzi/blob/master/1.%20Jupyter%20vs%20CLI.ipynb","timestamp":1672137901465}]}},"nbformat":4,"nbformat_minor":0}